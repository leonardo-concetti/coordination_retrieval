---
title: "Data preparation"
author: "Leonardo Concetti"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r Packages, include=FALSE, results='hide'}

library(tidyverse)

```


A function to read the results file from PCIbex 

```{r}

read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
          cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}

```


# Load the dataset, check submission integrity and quality.


Load the dataset

```{r}

dat <- read_csv("concetti24_coord_spr.csv")

```


Convert time stamps from Unix time to local time

```{r}

dat$local_time <- as.POSIXct(dat$Results.reception.time, origin="1970-01-01", tz="Europe/Rome")

```


Check number of subjects

```{r}

length(unique(dat$PROLIFIC_ID))

```


Check if someone failed the attention checks

```{r}

dat |> 
  filter(Label == "AttentionCheck", PennElementName == "Question") |> 
  summarise(attention_failed = sum(Value == "Si", na.rm = TRUE),
            attention_ok = sum(Value == "No", na.rm = TRUE))

dat |> 
  filter(Label == "AttentionCheck", PennElementName == "Question") |> 
  group_by(PROLIFIC_ID) |> 
  reframe(attention_check_answer = Value)

dat |> 
  filter(Label == "AttentionCheck", PennElementName == "Question") |> 
  group_by(PROLIFIC_ID) |> 
  summarise(attention_failed = sum(Value == "Si", na.rm = TRUE),
            attention_ok = sum(Value == "No", na.rm = TRUE))


```

# Start pre-processing


Get rid of practice phase, instructions etc

```{r}

dat <- dat |> 
  filter(Label %in% c("experimental-experimental", "experimental-filler"))

```


Remove useless columns

```{r}

dat <- dat |> 
  select(-Inner.element.number, -PennElementType, -Latin.Square.Group,
         -MD5.hash.of.participant.s.IP.address, -Newline., -Controller.name,
         -EventTime, -Comments, -STUDY_ID, -SESSION_ID, -Order.number.of.item, 
         -Results.reception.time)

```


Remove metadata from each trial starting parameter

```{r}

dat <- dat |> 
  filter(!Parameter %in% c("_Trial_", "_Header_"))

```


# Adding accuracy data column

Separate data from sentences and question/answer

```{r}

dat <- dat |> 
  mutate(selection = case_when(
    Value %in% c("Si", "No") ~ Value,
                               FALSE ~ NA_character_)
    )

```


Paste the selected answer to each row of that trial 

```{r}

 # Define a function to replace NA values with non-NA values within each group
replace_na_with_non_na <- function(x) {
  non_na_value <- na.omit(x)[1]  # Get the first non-NA value
  replace(x, is.na(x), non_na_value)  # Replace NA values with the non-NA value
}


dat <- dat |> 
  group_by(item, PROLIFIC_ID) |> 
  mutate(selection = replace_na_with_non_na(selection)) |> 
  ungroup()

```


Change "Si" into "si" and "No" into "no" to avoid confusion with capital letters

```{r}

dat <- dat |> 
  mutate(
    Value = case_when(
      Value == "Si" ~ "si",
      Value == "No" ~ "no",
      TRUE ~ Value
    ),
    selection = case_when(
      selection == "Si" ~ "si",
      selection == "No" ~ "no",
      TRUE ~ selection
    )
  )

```


Add a column with correct/incorrect answer info

```{r}

dat <- dat |> 
mutate(correct = if_else(answer == selection, 1, 0))

```


Remove answers rows

```{r}

dat <- dat |> 
  filter(!PennElementName == "Question")

```


Now we can remove Penn.element.name column 

```{r}

dat <- dat |> 
  select(-PennElementName)

```


# Manage NAs, RTs, participants IDs, colnames

Check Reading Time NAs

```{r}

any(is.na(dat$Reading.time))

```

Make sure RTs are interpreted as numbers and not characters

```{r}

class(dat$Reading.time)

dat <- dat |> 
  mutate(Reading.time = as.numeric(Reading.time))

class(dat$Reading.time)

```

Convert subject IDs to numbers starting from 1

```{r}

dat <- dat |> 
  mutate(PROLIFIC_ID = as.integer(factor(PROLIFIC_ID, levels = unique(PROLIFIC_ID))))

```


Rename columns to more manageable names 

```{r}

dat <- dat |> 
  rename(roi_value = Value, rt = Reading.time, sentence = Sentence..or.sentence.MD5.,
         roi_number = Parameter, list = group, subj = PROLIFIC_ID, label = Label)

```



Check design

```{r}

xtabs(~ subj + as.numeric(item), dat)

dat$roi_value[dat$roi_number == 10 & dat$condition != "fill"] #to check that the matrix verb is always in roi number 10

dat$roi_value[dat$roi_number == 5 & dat$condition != "fill"] #to check that the RC verb is always in roi number 5


```


# Quality checks


Check accuracy and mean RTs by participant, first on the whole session, then divided by experimental vs filler trials


```{r}

dat |> 
  group_by(subj) |> 
  summarize(mean_correct = round(mean(correct), 2), 
            rt = round(mean(rt, na.rm = TRUE), ))


dat |> 
  group_by(subj) |> 
  summarize(mean_correct_exp = round(mean(correct[item_type == "experimental"]), 2),
            mean_correct_fill = round(mean(correct[item_type == "filler"]), 2), 
            rt_exp = round(mean(rt[item_type == "experimental"], na.rm = TRUE), ),
            rt_fill = round(mean(rt[item_type == "filler"], na.rm = TRUE), ))
```


```{r}

dat |> 
  group_by(subj) |> 
  summarize(mean_correct_exp = round(mean(correct[item_type == "experimental"]), 2)) |> 
  filter(mean_correct_exp < 0.7)

```


*Lower-accuracy participants (< 85% global accuracy and/or very fast mean Reading Times):* 


- 5 = 0.87 (tot) with 252 mean_rt (tot) - 0.78 (exp) with 245 mean_rt (exp) and 0.95 (fill) with 259 mean_rt (fill)

- 9 = 0.82 (tot) with 424 mean_rt (tot) - 0.66 (exp) with 402 mean_rt (exp) and 0.98 (fill) with 445 mean_rt (fill)

- 71 = 0.77 (tot) with 430 mean_rt (tot) - 0.59 (exp) with 426 mean_rt (exp) and 0.93 (fill) with 434 mean_rt (fill)  			

- 86 = 0.76 (tot) with 318 mean_rt (tot) - 0.66 (exp) with 278 mean_rt (exp) and 0.85 (fill) with 355 mean_rt (fill)

- 88 = 0.85 (tot) with 295 mean_rt (tot) -	0.75 (exp) with 323 mean_rt (exp) and 0.95 (fill) with 269 mean_rt (fill)		

- 138 = 0.80 (tot) with 303 mean_rt (tot) - 0.72 (exp) with 287 mean_rt (exp) and 0.89 (fill) with 317 mean_rt (fill)

- 173 = 0.84 (tot) with 571 mean_rt (tot) - 0.69 (exp) with 586 mean_rt (exp) and 0.98 (fill) with 557 mean_rt (fill)

- 177 = 0.86 (tot) with 286 mean_rt (tot) - 0.78 (exp) with 277 mean_rt (exp) and 0.93 (fill) with 296 mean_rt (fill)

- 194 = 0.83 (tot) with 420 mean_rt (tot) - 0.72 (exp) with 413 mean_rt (exp) and 0.93 (fill) with 425 mean_rt (fill)


*Participants with ~ 75% acc on experimental items and/or weird RTs:* 

- 13 = 0.87 (tot) with 577 mean_rt (tot) - 0.78 (exp) with 603 mean_rt (exp) and 0.96 (fill)	with 553 mean_rt (fill)

- 44 = 0.86 (tot) with 710 mean_rt (tot) - 0.75 (exp) with 910 mean_rt (exp) and 0.97 (fill) with 520 mean_rt (fill)

- 164 =	0.87 (tot) with mean_rt	1060 (tot) - 0.81 (exp) with 1229 mean_rt (exp) and	0.93 (fill) with 898 mean_rt (fill)

- 185	 = 0.88 (tot) with 847 mean_rt (tot) - 0.78 (exp) with 452 mean_rt (exp) and 0.98 (fill) with 1223 mean_rt (fill)

- 199 = 0.96 (tot) with 2701	mean_rt (tot) - 0.97 (exp) with 4138 mean_rt (exp) and 0.95 (fill) with 1336 mean_rt (fill)

- 216	= 0.91 (tot) with 1892	mean_rt (tot) - 0.88 (exp) with 3397 mean_rt (exp) and 0.94 (fill) with 461 mean_rt (fill)

						
**We can decide to drop any participant with <70% accuracy on experimental items --> this would exclude subjects 9, 71, 86, 173**

Check mean RTs by ROI for each participant

```{r}

dat |> 
  group_by(subj) |> 
  filter(item_type == "experimental") |> 
  summarize(mean_correct = round(mean(correct), 2),
            rt_rc_pre = round(mean(rt[roi_number == 4], na.rm = TRUE), ),
            rt_rc = round(mean(rt[roi_number == 5], na.rm = TRUE), ),
            rt_rc_spill = round(mean(rt[roi_number == 6], na.rm = TRUE), ),
            rt_mv_pre = round(mean(rt[roi_number == 9], na.rm = TRUE), ),
            rt_mv = round(mean(rt[roi_number == 10], na.rm = TRUE), ),
            rt_mv_spill = round(mean(rt[roi_number == 11], na.rm = TRUE), ),
            rt_end = round(mean(rt[roi_number == 12], na.rm = TRUE), ),
            rt_tot = round(mean(rt, na.rm = TRUE), )
            )

```

73 = 2719ms on MV

165 = 2104ms on MV

166 = 2339ms on RCV

189 = 2686ms on RCV + 1655ms on pre_mv

199	= 2034	6343	3776	3481	3339	4963	9591 - 4138(tot)  - what was this guy doing??? (high accuracy though - 0.97)

216	= 36377 mean RT on sentence end - was he taking a pause after reading each sentence? maybe he paused the experiment a couple of times for various minutes and he did so at the end of sentence, before question time. If he did so only after EXP sentences, this explains his weird RT on exp items, but not on fillers, and also good accuracy. 

227 = 2902 on RCV (the rest looks normal and he has 100% accuracy on experimental items)
	
**Also consider removing subjects 199 or seeing if he has some impact on the results of the analysis**

# Last bits of cleaning


Get rid of the filler trials (only do this after having checked everything is ok, including accuracy of participants etc and having decided if/what subjects to exclude)

```{r}

dat <- dat |> 
  filter(condition != "fill")

```



Add a column for trial ID (*this only works after removing fillers!* fillers don't have a fixed length of 12 roi each)

```{r}

dat <- dat |> 
  group_by(subj) |> 
  mutate(trial = rep(1:(ceiling(n() / 12)), each = 12)[1:n()])

length(unique(dat$trial))


```

Check list assignment 

```{r}

dat |> 
    group_by(list) |> 
    summarise(n_subj = n_distinct(subj)) |> 
    mutate(percentage = (n_subj / sum(n_subj)) * 100)

```

It's expected that it does not result in a perfect 50-50 balance, as we cannot control which subject leave the task before its end, which ones get timed-out etc. But it's still pretty balanced, so nothing to worry about. 

Rename a couple of columns

```{r}

dat <- dat |> 
  rename(answer_expected = answer, answer_selected = selection)

```


Arrange the columns in the desired order

```{r}

dat <- dat |> 
  select(subj, list, trial, item, condition, roi_number, roi_value, rt, sentence, 
         question, question_type, answer_expected, answer_selected, correct)  #remember to add here any other column that you did not remove from the data frame

```


Have a look at the resulting df

```{r}

dat |> head(24)

```


# Save the clean dataset 

```{r}

write_csv(dat, r"[C:\Users\lconc\OneDrive - student.unisi.it\PhD - DISPOC\Projects\2 - Year 2\coordination_retrieval\coord_spr.csv]")

```